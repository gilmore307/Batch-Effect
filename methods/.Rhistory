y <- df_merged[[group_col]]
# One-vs-rest AUC per batch
for (b in batch_levels) {
y_bin <- as.numeric(y == b)
model <- try(glm(y_bin ~ ., data = cbind(y_bin, X), family = "binomial"), silent = TRUE)
if (!inherits(model, "try-error")) {
pred <- predict(model, newdata = X, type = "response")
roc_obj <- roc(y_bin, pred, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
auc_matrix[method, paste0("Batch_", b)] <- auc_val
}
}
}
return(auc_matrix)
}
# ==== Compute AUC Matrix ====
auc_mat <- compute_auc_matrix(file_list, metadata, group_col = "batchid")
# ==== Plot Heatmap ====
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Batch Separability AUC",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)  # AUC range [0.5, 1]
)
# ==== Load Libraries ====
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
metadata$group <- as.factor(metadata$group)  # ← CHANGE THIS TO YOUR VARIABLE
install.packages(c("dplyr", "tidyr", "ggplot2", "vegan", "caret", "randomForest", "e1071", "glmnet"))
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("curatedMetagenomicData")
source("real_data_obtain.R")
# ==== Load Libraries ====
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
metadata$group <- as.factor(metadata$group)  # ← CHANGE THIS TO YOUR VARIABLE
# ==== Load Libraries ====
install.packages(c("pROC", "pheatmap", "readr", "dplyr", "nnet"))
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)  # for multinom
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Function to Compute AUC per Batch ====
compute_auc_matrix <- function(file_list, metadata, group_col = "batchid") {
method_names <- names(file_list)
batch_levels <- sort(unique(metadata[[group_col]]))
auc_matrix <- matrix(NA, nrow = length(method_names), ncol = length(batch_levels),
dimnames = list(method_names, paste0("Batch_", batch_levels)))
for (method in method_names) {
df <- read_csv(file_list[[method]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Get numeric features and batch
X <- df_merged %>% select(where(is.numeric)) %>% select_if(~ sd(.) > 0)
y <- df_merged[[group_col]]
# One-vs-rest AUC per batch
for (b in batch_levels) {
y_bin <- as.numeric(y == b)
model <- try(glm(y_bin ~ ., data = cbind(y_bin, X), family = "binomial"), silent = TRUE)
if (!inherits(model, "try-error")) {
pred <- predict(model, newdata = X, type = "response")
roc_obj <- roc(y_bin, pred, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
auc_matrix[method, paste0("Batch_", b)] <- auc_val
}
}
}
return(auc_matrix)
}
# ==== Compute AUC Matrix ====
auc_mat <- compute_auc_matrix(file_list, metadata, group_col = "batchid")
# ==== Plot Heatmap ====
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Batch Separability AUC (Higher = Worse Correction)",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)  # AUC range [0.5, 1]
)
# ==== Load Libraries ====
install.packages(c("pROC", "pheatmap", "readr", "dplyr", "nnet"))
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)  # for multinom
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Function to Compute AUC per Batch ====
compute_auc_matrix <- function(file_list, metadata, group_col = "batchid") {
method_names <- names(file_list)
batch_levels <- sort(unique(metadata[[group_col]]))
auc_matrix <- matrix(NA, nrow = length(method_names), ncol = length(batch_levels),
dimnames = list(method_names, paste0("Batch_", batch_levels)))
for (method in method_names) {
df <- read_csv(file_list[[method]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Get numeric features and batch
X <- df_merged %>% select(where(is.numeric)) %>% select_if(~ sd(.) > 0)
y <- df_merged[[group_col]]
# One-vs-rest AUC per batch
for (b in batch_levels) {
y_bin <- as.numeric(y == b)
model <- try(glm(y_bin ~ ., data = cbind(y_bin, X), family = "binomial"), silent = TRUE)
if (!inherits(model, "try-error")) {
pred <- predict(model, newdata = X, type = "response")
roc_obj <- roc(y_bin, pred, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
auc_matrix[method, paste0("Batch_", b)] <- auc_val
}
}
}
return(auc_matrix)
}
# ==== Compute AUC Matrix ====
auc_mat <- compute_auc_matrix(file_list, metadata, group_col = "batchid")
# ==== Plot Heatmap ====
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Population Effect AUC",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)  # AUC range [0.5, 1]
)
install.packages(c("pROC", "pheatmap", "readr", "dplyr", "nnet"))
# normalize_all_methods.R
# Normalize ConQuR sample data using various methods: ConQuR, ALRA, BDMMA, PLSDAbatch, ComBat, FSQN
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
# Optional: Load if installed
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
setwd('C:/Users/sunch/Desktop/Project/Batch-Effect/methods')
data("Sample_Data", package = "ConQuR")
taxa_mat <- Sample_Data[, 1:100]
metadata <- Sample_Data[, 101:ncol(Sample_Data)]
sample_ids <- rownames(Sample_Data)
metadata$sample_id <- rownames(Sample_Data)
covar <- Sample_Data[, c("sbp", "sex", "race", "age")]  # Metadata
batchid <- factor(Sample_Data$batchid)
write.csv(taxa_mat, file = "raw.csv", row.names = FALSE)
write.csv(metadata, file = "metadata.csv", row.names = FALSE)
taxa_rel_abund <- sweep(taxa_mat, 1, rowSums(taxa_mat), "/")
taxa_rel_abund[is.na(taxa_rel_abund)] <- 0
taxa_log <- log2(taxa_rel_abund + 1e-6)
taxa_log_t <- t(taxa_log)
combat_corrected <- ComBat(dat = taxa_log_t, batch = batchid, mod = NULL, par.prior = TRUE, prior.plots = FALSE)
combat_corrected_final <- t(combat_corrected)
scaled_data <- scale(combat_corrected_final)
taxa_rel_corrected <- 2^scaled_data
write.csv(taxa_rel_corrected, "normalized_combat.csv", row.names = FALSE)
rownames(taxa_mat) <- rownames(Sample_Data)
taxa_clr <- clr(taxa_mat + 1)
Y.trt <- ifelse(metadata$sbp > 130, "high", "normal")    # binary treatment/class
Y.bat <- as.factor(metadata$batchid)
result <- PLSDA_batch(X = taxa_clr, Y.trt = Y.trt, Y.bat = Y.bat,
ncomp.trt = 1, ncomp.bat = 5)
corrected_data <- result$X.nobatch
write.csv(corrected_data, "normalized_plsda.csv", row.names = FALSE)
# ==== Load Libraries ====
library(FNN)
library(readr)
library(dplyr)
library(ggplot2)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Alignment Score Function ====
compute_alignment_score <- function(data, batch_vector, k = 10) {
# Run PCA
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:10]  # use first 10 PCs
# Find k-nearest neighbors
knn_result <- get.knn(coords, k = k)
neighbors <- knn_result$nn.index
# Compute alignment score
alignment_scores <- sapply(1:nrow(data), function(i) {
neighbor_batches <- batch_vector[neighbors[i, ]]
mean(neighbor_batches != batch_vector[i])  # fraction of neighbors from other batches
})
return(mean(alignment_scores))
}
# ==== Compute Scores for All Methods ====
alignment_scores <- data.frame(Method = character(), Score = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- df_merged$batchid
score <- compute_alignment_score(X, batch, k = 10)
alignment_scores <- rbind(alignment_scores, data.frame(Method = name, Score = score))
}
# ==== Plot Alignment Scores ====
ggplot(alignment_scores, aes(x = reorder(Method, Score), y = Score, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Comparison of alignment scores",
x = "Method",
y = "Alignment Score"
) +
ylim(0, 1) +
theme_minimal(base_size = 14)
# ==== Load Libraries ====
install.packages(c("pROC", "pheatmap", "readr", "dplyr", "nnet"))
# ==== Load Libraries ====
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)  # for multinom
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Function to Compute AUC per Batch ====
compute_auc_matrix <- function(file_list, metadata, group_col = "batchid") {
method_names <- names(file_list)
batch_levels <- sort(unique(metadata[[group_col]]))
auc_matrix <- matrix(NA, nrow = length(method_names), ncol = length(batch_levels),
dimnames = list(method_names, paste0("Batch_", batch_levels)))
for (method in method_names) {
df <- read_csv(file_list[[method]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Get numeric features and batch
X <- df_merged %>% select(where(is.numeric)) %>% select_if(~ sd(.) > 0)
y <- df_merged[[group_col]]
# One-vs-rest AUC per batch
for (b in batch_levels) {
y_bin <- as.numeric(y == b)
model <- try(glm(y_bin ~ ., data = cbind(y_bin, X), family = "binomial"), silent = TRUE)
if (!inherits(model, "try-error")) {
pred <- predict(model, newdata = X, type = "response")
roc_obj <- roc(y_bin, pred, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
auc_matrix[method, paste0("Batch_", b)] <- auc_val
}
}
}
return(auc_matrix)
}
# ==== Compute AUC Matrix ====
auc_mat <- compute_auc_matrix(file_list, metadata, group_col = "batchid")
# ==== Plot Heatmap ====
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Population Effect AUC",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)  # AUC range [0.5, 1]
)
# ==== Load Required Libraries ====
install.packages("vegan")
# ==== Load Required Libraries ====
library(vegan)
library(pheatmap)
library(readr)
library(dplyr)
library(gridExtra)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Bray-Curtis Batch-Level Heatmap Generator (returns gtable) ====
generate_batch_heatmap_gtable <- function(file_path, method_name, metadata, group_col = "batchid") {
df <- read_csv(file_path)
# Align sample_id with metadata
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Extract taxa matrix
taxa <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
sample_ids <- df_merged$sample_id
batches <- df_merged[[group_col]]
# Compute Bray-Curtis distance
dist_mat <- vegdist(taxa, method = "bray")
dist_df <- as.matrix(dist_mat)
rownames(dist_df) <- colnames(dist_df) <- sample_ids
# Get unique batches
batch_levels <- sort(unique(na.omit(batches)))
batch_dist_mat <- matrix(NA, length(batch_levels), length(batch_levels),
dimnames = list(batch_levels, batch_levels))
for (i in batch_levels) {
for (j in batch_levels) {
samples_i <- sample_ids[batches == i]
samples_j <- sample_ids[batches == j]
sub_dists <- dist_df[samples_i, samples_j, drop = FALSE]
batch_dist_mat[i, j] <- mean(sub_dists, na.rm = TRUE)
}
}
# Replace NAs
batch_dist_mat[is.na(batch_dist_mat)] <- 0
# Avoid flat matrix issues
if (length(unique(c(batch_dist_mat))) == 1) {
batch_dist_mat <- batch_dist_mat + matrix(runif(length(batch_dist_mat), -1e-6, 1e-6),
nrow = nrow(batch_dist_mat))
}
# Breaks
max_val <- max(batch_dist_mat)
breaks <- seq(0, max_val, length.out = 101)
# Return gtable (not plot)
p <- pheatmap(
batch_dist_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 14,
fontsize = 14,
main = paste("Inter-Batch Bray-Curtis -", method_name),
breaks = breaks,
silent = TRUE  # <- return gtable object
)
return(p$gtable)
}
# ==== Generate All Heatmaps as gtable ====
heatmap_list <- lapply(names(file_list), function(name) {
generate_batch_heatmap_gtable(file_list[[name]], name, metadata)
})
# ==== Combine and Display ====
grid.arrange(grobs = heatmap_list, ncol = 2)
# ==== Load Required Libraries ====
library(ggplot2)
library(patchwork)
library(readr)
library(dplyr)
library(ggfortify)
library(cluster)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
# ==== File Paths ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== PCA Plot Function Using Metadata Grouping ====
pca_with_metadata_plot <- function(df, method_name, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id  # Add sample_id from metadata
# Merge with metadata
df_merged <- inner_join(df, metadata, by = "sample_id")
# Extract numeric columns excluding the grouping column
df_num <- df_merged %>%
select(where(is.numeric)) %>%
select(-any_of(group_col))
# Convert group column to factor
df_group <- df_merged %>%
mutate(group = as.factor(!!sym(group_col))) %>%
select(group)
# Remove constant columns
df_num <- df_num[, apply(df_num, 2, function(x) sd(x) > 0), drop = FALSE]
# PCA
pca <- prcomp(df_num, scale. = TRUE)
# Plot with group as color
autoplot(
pca,
data = df_group,
colour = "group",
frame = TRUE,
frame.type = "norm",
main = paste("PCA -", method_name)
) +
theme_minimal()
}
# ==== Apply PCA Plotting with Metadata Coloring ====
plots <- lapply(names(file_list), function(name) {
df <- read_csv(file_list[[name]])
pca_with_metadata_plot(df, name, metadata, group_col = "batchid")
})
# ==== Combine All Plots ====
combined_plot <- wrap_plots(plots, ncol = 2)
print(combined_plot)
# ==== Load Required Libraries ====
library(ConQuR)
library(readr)
library(dplyr)
# ==== Read Metadata ====
metadata <- read_csv("metadata.csv")
metadata$sample_id <- as.character(metadata$sample_id)
# ==== File Paths for Datasets ====
file_list <- list(
Raw = "raw.csv",
ALRA = "normalized_alra.csv",
ComBat = "normalized_combat.csv",
ConQuR = "normalized_conqur.csv",
FSQN = "normalized_fsqn.csv",
PLSDA = "normalized_plsda.csv"
)
# ==== Combine All PCoA Plots into One Page ====
# Set up a 3x2 layout (for 6 methods)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # Adjust margins as needed
# Loop through files and plot each using Plot_PCoA
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
taxa <- df_merged %>% select(where(is.numeric)) %>% as.matrix()
group <- df_merged$batchid
Plot_PCoA(
TAX = taxa,
factor = group,
dissimilarity = "Bray",
main = paste("PCoA -", name)
)
}
par(mfrow = c(1, 1))
