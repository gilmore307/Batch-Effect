df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Filter out any incomplete rows
df_merged <- df_merged %>% filter(complete.cases(.))
batches <- df_merged[[group_col]]
sample_ids <- df_merged$sample_id
features <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(., na.rm = TRUE) > 0) %>%
as.matrix()
batch_levels <- sort(unique(batches))
rmse_mat <- matrix(NA, nrow = length(batch_levels), ncol = length(batch_levels),
dimnames = list(batch_levels, batch_levels))
# Normalize RMSE matrix to 0-1 range
min_val <- min(rmse_mat, na.rm = TRUE)
max_val <- max(rmse_mat, na.rm = TRUE)
rmse_mat <- (rmse_mat - min_val) / (max_val - min_val)
rmse_mat <- round(rmse_mat, 2)
for (i in batch_levels) {
for (j in batch_levels) {
X_i <- features[batches == i, , drop = FALSE]
X_j <- features[batches == j, , drop = FALSE]
if (nrow(X_i) > 0 && nrow(X_j) > 0) {
X_i_mean <- colMeans(X_i, na.rm = TRUE)
X_j_mean <- colMeans(X_j, na.rm = TRUE)
rmse <- sqrt(mean((X_i_mean - X_j_mean)^2))
rmse_mat[as.character(i), as.character(j)] <- round(rmse, 2)
}
}
}
return(rmse_mat)
}
# ==== RMSE Heatmap Plot Function ====
generate_rmse_heatmap_gtable <- function(file_path, method_name, metadata) {
df <- read_csv(file_path)
rmse_mat <- compute_rmse_matrix(df, metadata)
if (all(is.na(rmse_mat))) {
return(grid.text(paste("Insufficient data:", method_name)))
}
max_val <- max(rmse_mat, na.rm = TRUE)
breaks <- seq(0, max_val, length.out = 101)
p <- pheatmap(
rmse_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 14,
fontsize = 14,
main = paste("Inter-Batch RMSE -", method_name),
color = colorRampPalette(c("blue", "white", "red"))(100),
breaks = breaks,
na_col = "gray",
silent = TRUE
)
print(paste("RMSE matrix for method:", method_name))
print(rmse_mat)
return(p$gtable)
}
# ==== Generate All Heatmaps ====
rmse_heatmap_list <- lapply(names(file_list), function(name) {
generate_rmse_heatmap_gtable(file_list[[name]], name, metadata)
})
# ==== Save Combined RMSE Heatmaps ====
tiff(file.path(output_folder, "rmse.tiff"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
png(file.path(output_folder, "rmse.png"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
# ==== Load Required Libraries ====
library(pheatmap)
library(readr)
library(dplyr)
library(gridExtra)
library(grid)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # For testing; replace in production
if (length(args) < 1) stop("Usage: Rscript rmse_heatmap.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== RMSE Matrix Computation ====
compute_rmse_matrix <- function(df, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Filter out any incomplete rows
df_merged <- df_merged %>% filter(complete.cases(.))
batches <- df_merged[[group_col]]
sample_ids <- df_merged$sample_id
features <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(., na.rm = TRUE) > 0) %>%
as.matrix()
batch_levels <- sort(unique(batches))
rmse_mat <- matrix(NA, nrow = length(batch_levels), ncol = length(batch_levels),
dimnames = list(batch_levels, batch_levels))
# Normalize RMSE matrix to 0-1 range
min_val <- min(rmse_mat, na.rm = TRUE)
max_val <- max(rmse_mat, na.rm = TRUE)
rmse_mat <- (rmse_mat - min_val) / (max_val - min_val)
rmse_mat <- round(rmse_mat, 2)
for (i in batch_levels) {
for (j in batch_levels) {
X_i <- features[batches == i, , drop = FALSE]
X_j <- features[batches == j, , drop = FALSE]
if (nrow(X_i) > 0 && nrow(X_j) > 0) {
X_i_mean <- colMeans(X_i, na.rm = TRUE)
X_j_mean <- colMeans(X_j, na.rm = TRUE)
rmse <- sqrt(mean((X_i_mean - X_j_mean)^2))
rmse_mat[as.character(i), as.character(j)] <- round(rmse, 2)
}
}
}
return(rmse_mat)
}
# ==== RMSE Heatmap Plot Function ====
generate_rmse_heatmap_gtable <- function(file_path, method_name, metadata) {
df <- read_csv(file_path)
rmse_mat <- compute_rmse_matrix(df, metadata)
if (all(is.na(rmse_mat))) {
return(grid.text(paste("Insufficient data:", method_name)))
}
max_val <- max(rmse_mat, na.rm = TRUE)
breaks <- seq(0, max_val, length.out = 101)
p <- pheatmap(
rmse_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 14,
fontsize = 14,
main = paste("Inter-Batch RMSE -", method_name),
color = colorRampPalette(c("blue", "white", "red"))(100),
breaks = breaks,
na_col = "gray",
silent = TRUE
)
print(paste("RMSE matrix for method:", method_name))
print(rmse_mat)
return(p$gtable)
}
# ==== Generate All Heatmaps ====
rmse_heatmap_list <- lapply(names(file_list), function(name) {
generate_rmse_heatmap_gtable(file_list[[name]], name, metadata)
})
# ==== Save Combined RMSE Heatmaps ====
tiff(file.path(output_folder, "rmse.tiff"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
png(file.path(output_folder, "rmse.png"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
# ==== Load Required Libraries ====
library(pheatmap)
library(readr)
library(dplyr)
library(gridExtra)
library(grid)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # For testing; replace in production
if (length(args) < 1) stop("Usage: Rscript rmse_heatmap.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== RMSE Matrix Computation ====
compute_rmse_matrix <- function(df, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Filter out any incomplete rows
df_merged <- df_merged %>% filter(complete.cases(.))
batches <- df_merged[[group_col]]
sample_ids <- df_merged$sample_id
features <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(., na.rm = TRUE) > 0) %>%
as.matrix()
batch_levels <- sort(unique(batches))
rmse_mat <- matrix(NA, nrow = length(batch_levels), ncol = length(batch_levels),
dimnames = list(batch_levels, batch_levels))
for (i in batch_levels) {
for (j in batch_levels) {
X_i <- features[batches == i, , drop = FALSE]
X_j <- features[batches == j, , drop = FALSE]
if (nrow(X_i) > 0 && nrow(X_j) > 0) {
X_i_mean <- colMeans(X_i, na.rm = TRUE)
X_j_mean <- colMeans(X_j, na.rm = TRUE)
rmse <- sqrt(mean((X_i_mean - X_j_mean)^2))
rmse_mat[as.character(i), as.character(j)] <- round(rmse, 2)
}
}
}
# Normalize RMSE matrix to 0-1 range
min_val <- min(rmse_mat, na.rm = TRUE)
max_val <- max(rmse_mat, na.rm = TRUE)
rmse_mat <- (rmse_mat - min_val) / (max_val - min_val)
rmse_mat <- round(rmse_mat, 2)
return(rmse_mat)
}
# ==== RMSE Heatmap Plot Function ====
generate_rmse_heatmap_gtable <- function(file_path, method_name, metadata) {
df <- read_csv(file_path)
rmse_mat <- compute_rmse_matrix(df, metadata)
if (all(is.na(rmse_mat))) {
return(grid.text(paste("Insufficient data:", method_name)))
}
max_val <- max(rmse_mat, na.rm = TRUE)
breaks <- seq(0, max_val, length.out = 101)
p <- pheatmap(
rmse_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 14,
fontsize = 14,
main = paste("Inter-Batch RMSE -", method_name),
color = colorRampPalette(c("blue", "white", "red"))(100),
breaks = breaks,
na_col = "gray",
silent = TRUE
)
print(paste("RMSE matrix for method:", method_name))
print(rmse_mat)
return(p$gtable)
}
# ==== Generate All Heatmaps ====
rmse_heatmap_list <- lapply(names(file_list), function(name) {
generate_rmse_heatmap_gtable(file_list[[name]], name, metadata)
})
# ==== Save Combined RMSE Heatmaps ====
tiff(file.path(output_folder, "rmse.tiff"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
png(file.path(output_folder, "rmse.png"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = rmse_heatmap_list, ncol = 2)
dev.off()
# ==== Load Libraries ====
library(FNN)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # Replace for actual usage
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Entropy Function ====
compute_entropy_score <- function(data, batch_labels, k = 10) {
# PCA first to reduce dimensions
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:min(nrow(data)-1, 10)]
# Get k-nearest neighbors
neighbors <- get.knn(coords, k = k)$nn.index
# Compute entropy for each sample
entropy_vec <- sapply(1:nrow(coords), function(i) {
neighbor_batches <- batch_labels[neighbors[i, ]]
freq <- table(neighbor_batches) / k
-sum(freq * log2(freq + 1e-10))  # add small value to avoid log(0)
})
mean(entropy_vec)
}
# ==== Compute Entropy Scores for Each Method ====
entropy_scores <- data.frame(Method = character(), Entropy = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- as.factor(df_merged$batchid)
entropy <- compute_entropy_score(X, batch, k = 10)
entropy_scores <- rbind(entropy_scores, data.frame(Method = name, Entropy = entropy))
}
# ==== Plot ====
plot <- ggplot(entropy_scores, aes(x = reorder(Method, Entropy), y = Entropy, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Entropy of Batch Mixing (Higher = Better)",
x = "Method",
y = "Entropy"
) +
ylim(0, log2(length(unique(metadata$batchid)))) +
theme_minimal(base_size = 14)
# ==== Save Plots ====
ggsave(file.path(output_folder, "entropy_batch_mixing.tif"), plot, width = 10, height = 8, dpi = 300)
ggsave(file.path(output_folder, "entropy_batch_mixing.png"), plot, width = 10, height = 8, dpi = 300)
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
# ==== Save Plots ====
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
# ==== Load Libraries ====
library(FNN)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # Replace for actual usage
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Entropy Function ====
compute_entropy_score <- function(data, batch_labels, k = 10) {
# PCA first to reduce dimensions
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:min(nrow(data)-1, 10)]
# Get k-nearest neighbors
neighbors <- get.knn(coords, k = k)$nn.index
# Compute entropy for each sample
entropy_vec <- sapply(1:nrow(coords), function(i) {
neighbor_batches <- batch_labels[neighbors[i, ]]
freq <- table(neighbor_batches) / k
-sum(freq * log2(freq + 1e-10))  # add small value to avoid log(0)
})
mean(entropy_vec)
}
# ==== Compute Entropy Scores for Each Method ====
entropy_scores <- data.frame(Method = character(), Entropy = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- as.factor(df_merged$batchid)
entropy <- compute_entropy_score(X, batch, k = 10)
entropy_scores <- rbind(entropy_scores, data.frame(Method = name, Entropy = entropy))
}
# ==== Plot ====
plot <- ggplot(entropy_scores, aes(x = reorder(Method, Entropy), y = Entropy, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Entropy of Batch Mixing (Higher = Better)",
x = "Method",
y = "Entropy"
) +
ylim(0, log2(length(unique(metadata$batchid)))) +
theme_minimal(base_size = 14)
# ==== Save Plots ====
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
# Save as TIFF (high-quality)
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# Save as PNG (lightweight alternative)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
install.packages("remotes")
remotes::install_github("madhulika-EBI/Batchevaluation")
# ==== Load Libraries ====
library(FNN)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # Replace for actual usage
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Entropy Function ====
compute_entropy_score <- function(data, batch_labels, k = 10) {
# PCA first to reduce dimensions
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:min(nrow(data)-1, 10)]
# Get k-nearest neighbors
neighbors <- get.knn(coords, k = k)$nn.index
# Compute entropy for each sample
entropy_vec <- sapply(1:nrow(coords), function(i) {
neighbor_batches <- batch_labels[neighbors[i, ]]
freq <- table(neighbor_batches) / k
-sum(freq * log2(freq + 1e-10))  # add small value to avoid log(0)
})
mean(entropy_vec)
}
# ==== Compute Entropy Scores for Each Method ====
entropy_scores <- data.frame(Method = character(), Entropy = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- as.factor(df_merged$batchid)
entropy <- compute_entropy_score(X, batch, k = 10)
entropy_scores <- rbind(entropy_scores, data.frame(Method = name, Entropy = entropy))
}
# ==== Plot ====
plot <- ggplot(entropy_scores, aes(x = reorder(Method, Entropy), y = Entropy, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Entropy of Batch Mixing",
x = "Method",
y = "Entropy"
) +
ylim(0, log2(length(unique(metadata$batchid)))) +
theme_minimal(base_size = 14)
# ==== Save Plots ====
# Save as TIFF (high-quality)
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# Save as PNG (lightweight alternative)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# ==== Load Libraries ====
library(FNN)
library(dplyr)
library(readr)
library(ggplot2)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # Replace for actual usage
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Entropy Function ====
compute_entropy_score <- function(data, batch_labels, k = 10) {
# PCA first to reduce dimensions
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:min(nrow(data)-1, 10)]
# Get k-nearest neighbors
neighbors <- get.knn(coords, k = k)$nn.index
# Compute entropy for each sample
entropy_vec <- sapply(1:nrow(coords), function(i) {
neighbor_batches <- batch_labels[neighbors[i, ]]
freq <- table(neighbor_batches) / k
-sum(freq * log2(freq + 1e-10))  # add small value to avoid log(0)
})
mean(entropy_vec)
}
# ==== Compute Entropy Scores for Each Method ====
entropy_scores <- data.frame(Method = character(), Entropy = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- as.factor(df_merged$batchid)
entropy <- compute_entropy_score(X, batch, k = 10)
entropy_scores <- rbind(entropy_scores, data.frame(Method = name, Entropy = entropy))
}
# ==== Plot ====
plot <- ggplot(entropy_scores, aes(x = reorder(Method, Entropy), y = Entropy, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Entropy of Batch Mixing",
x = "Method",
y = "Entropy"
) +
ylim(0, log2(length(unique(metadata$batchid)))) +
theme_minimal(base_size = 14)
# ==== Save Plots ====
# Save as TIFF (high-quality)
tiff(file.path(output_folder, "entropy_batch_mixing.tif"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# Save as PNG (lightweight alternative)
png(file.path(output_folder, "entropy_batch_mixing.png"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
