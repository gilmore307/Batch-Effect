Y.bat <- as.factor(metadata$batchid)
result <- PLSDA_batch(X = taxa_clr, Y.trt = Y.trt, Y.bat = Y.bat, ncomp.trt = 1, ncomp.bat = 5)
write.csv(result$X.nobatch, file.path(output_folder, "normalized_plsda.csv"), row.names = FALSE)
}
if ("ComBat" %in% method_list) {
cat("Running ComBat...\n")
taxa_rel_abund <- sweep(taxa_mat, 1, rowSums(taxa_mat), "/")
taxa_rel_abund[is.na(taxa_rel_abund)] <- 0
taxa_log <- log2(taxa_rel_abund + 1e-6)
taxa_log_t <- t(taxa_log)
combat_corrected <- ComBat(dat = taxa_log_t, batch = batchid, mod = NULL, par.prior = TRUE, prior.plots = FALSE)
scaled_data <- scale(t(combat_corrected))
taxa_rel_corrected <- 2^scaled_data
write.csv(taxa_rel_corrected, file.path(output_folder, "normalized_combat.csv"), row.names = FALSE)
}
if ("FSQN" %in% method_list) {
cat("Running FSQN...\n")
reference_batch <- 0  # explicitly use batchid == 0
ref_matrix <- taxa_mat[batchid == reference_batch, , drop = FALSE]
reference_distribution <- apply(ref_matrix, 2, function(x) sort(x))
reference_target <- apply(reference_distribution, 1, median)
normalize_to_reference <- function(mat, target_vector) {
apply(mat, 2, function(feature_column) {
ranked <- rank(feature_column, ties.method = "min")
normalized <- target_vector[ranked]
return(normalized)
})
}
normalized_list <- lapply(unique(batchid), function(batch) {
mat <- taxa_mat[batchid == batch, , drop = FALSE]
normed <- normalize_to_reference(mat, reference_target)
rownames(normed) <- rownames(mat)
return(normed)
})
normalized_matrix <- do.call(rbind, normalized_list)
normalized_matrix <- normalized_matrix[rownames(taxa_mat), ]
write.csv(normalized_matrix, file.path(output_folder, "normalized_fsqn.csv"), row.names = FALSE)
}
# ==== Load Libraries ====
library(FNN)
library(readr)
library(dplyr)
library(ggplot2)
# ==== Handle Argument ====
#args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")
if (length(args) < 1) stop("Usage: Rscript alignment_score.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata_path <- file.path(output_folder, "metadata.csv")
metadata <- read_csv(metadata_path)
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Alignment Score Function ====
compute_alignment_score <- function(data, batch_vector, k = 10) {
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:10]
neighbors <- get.knn(coords, k = k)$nn.index
mean(sapply(1:nrow(data), function(i) {
neighbor_batches <- batch_vector[neighbors[i, ]]
mean(neighbor_batches != batch_vector[i])
}))
}
# ==== Compute Scores ====
alignment_scores <- data.frame(Method = character(), Score = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- df_merged$batchid
score <- compute_alignment_score(X, batch, k = 10)
alignment_scores <- rbind(alignment_scores, data.frame(Method = name, Score = score))
}
# ==== Plot and Save ====
plot <- ggplot(alignment_scores, aes(x = reorder(Method, Score), y = Score, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Comparison of Alignment Scores",
x = "Method",
y = "Alignment Score"
) +
ylim(0, 1) +
theme_minimal(base_size = 14)
# Save as TIFF (high-quality)
tiff(file.path(output_folder, "alignment_score.tif"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# Save as PNG (lightweight alternative)
png(file.path(output_folder, "alignment_score.png"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# ==== Load Required Libraries ====
library(ggplot2)
library(patchwork)
library(readr)
library(dplyr)
library(vegan)
library(ggfortify)
# ==== Read UID argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # for testing; comment out in production
if (length(args) < 1) stop("Usage: Rscript pcoa.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== PCoA Plot Function ====
pcoa_with_metadata_plot <- function(df, method_name, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
df_num <- df_merged %>%
select(where(is.numeric)) %>%
select(-any_of(group_col))
# Remove NA-only and constant columns
df_num <- df_num[, colSums(!is.na(df_num)) > 0, drop = FALSE]
df_num <- df_num[, apply(df_num, 2, function(x) sd(x, na.rm = TRUE)) > 0, drop = FALSE]
# Remove rows with NA values
complete_rows <- complete.cases(df_num)
df_num <- df_num[complete_rows, , drop = FALSE]
df_merged <- df_merged[complete_rows, , drop = FALSE]
rownames(df_num) <- df_merged$sample_id
# Compute Bray-Curtis distance and run PCoA
dist_mat <- vegdist(df_num, method = "bray")
pcoa_res <- cmdscale(dist_mat, k = 2, eig = TRUE)
points_df <- as.data.frame(pcoa_res$points)
colnames(points_df) <- c("PC1", "PC2")
fake_prcomp <- list(
x = as.matrix(points_df),
sdev = sqrt(abs(pcoa_res$eig[1:2])),
center = FALSE,
scale = FALSE,
rotation = matrix(0, nrow = ncol(df_num), ncol = 2)
)
rownames(fake_prcomp$rotation) <- colnames(df_num)
colnames(fake_prcomp$rotation) <- c("PC1", "PC2")
class(fake_prcomp) <- "prcomp"
df_group <- df_merged %>%
mutate(group = as.factor(!!sym(group_col))) %>%
select(group)
autoplot(fake_prcomp, data = df_group, colour = "group", frame = TRUE, frame.type = "norm",
main = paste("PCoA -", method_name)) +
theme_minimal()
}
# ==== Generate All PCoA Plots ====
pcoa_plots <- lapply(names(file_list), function(name) {
df <- read_csv(file_list[[name]])
pcoa_with_metadata_plot(df, name, metadata, group_col = "batchid")
})
# ==== Combine and Save ====
combined_pcoa <- wrap_plots(pcoa_plots, ncol = 2)
ggsave(file.path(output_folder, "pcoa.tif"), combined_pcoa, width = 12, height = 10, dpi = 300)
ggsave(file.path(output_folder, "pcoa.png"), combined_pcoa, width = 12, height = 10, dpi = 300)
# ==== Load Libraries ====
library(FNN)
library(readr)
library(dplyr)
library(ggplot2)
# ==== Handle Argument ====
#args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")
if (length(args) < 1) stop("Usage: Rscript alignment_score.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata_path <- file.path(output_folder, "metadata.csv")
metadata <- read_csv(metadata_path)
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Alignment Score Function ====
compute_alignment_score <- function(data, batch_vector, k = 10) {
pca <- prcomp(data, scale. = TRUE)
coords <- pca$x[, 1:10]
neighbors <- get.knn(coords, k = k)$nn.index
mean(sapply(1:nrow(data), function(i) {
neighbor_batches <- batch_vector[neighbors[i, ]]
mean(neighbor_batches != batch_vector[i])
}))
}
# ==== Compute Scores ====
alignment_scores <- data.frame(Method = character(), Score = numeric())
for (name in names(file_list)) {
df <- read_csv(file_list[[name]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(.) > 0) %>%
as.matrix()
batch <- df_merged$batchid
score <- compute_alignment_score(X, batch, k = 10)
alignment_scores <- rbind(alignment_scores, data.frame(Method = name, Score = score))
}
# ==== Plot and Save ====
plot <- ggplot(alignment_scores, aes(x = reorder(Method, Score), y = Score, fill = Method)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(
title = "Comparison of Alignment Scores",
x = "Method",
y = "Alignment Score"
) +
ylim(0, 1) +
theme_minimal(base_size = 14)
# Save as TIFF (high-quality)
tiff(file.path(output_folder, "alignment_score.tif"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# Save as PNG (lightweight alternative)
png(file.path(output_folder, "alignment_score.png"), width = 1000, height = 800, res = 150)
print(plot)
dev.off()
# ==== Load Required Libraries ====
library(ggplot2)
library(patchwork)
library(readr)
library(dplyr)
library(vegan)
library(ggfortify)
# ==== Read UID argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # for testing; comment out in production
if (length(args) < 1) stop("Usage: Rscript pcoa.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== PCoA Plot Function ====
pcoa_with_metadata_plot <- function(df, method_name, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
df_num <- df_merged %>%
select(where(is.numeric)) %>%
select(-any_of(group_col))
# Remove NA-only and constant columns
df_num <- df_num[, colSums(!is.na(df_num)) > 0, drop = FALSE]
df_num <- df_num[, apply(df_num, 2, function(x) sd(x, na.rm = TRUE)) > 0, drop = FALSE]
# Remove rows with NA values
complete_rows <- complete.cases(df_num)
df_num <- df_num[complete_rows, , drop = FALSE]
df_merged <- df_merged[complete_rows, , drop = FALSE]
rownames(df_num) <- df_merged$sample_id
# Compute Bray-Curtis distance and run PCoA
dist_mat <- vegdist(df_num, method = "bray")
pcoa_res <- cmdscale(dist_mat, k = 2, eig = TRUE)
points_df <- as.data.frame(pcoa_res$points)
colnames(points_df) <- c("PC1", "PC2")
fake_prcomp <- list(
x = as.matrix(points_df),
sdev = sqrt(abs(pcoa_res$eig[1:2])),
center = FALSE,
scale = FALSE,
rotation = matrix(0, nrow = ncol(df_num), ncol = 2)
)
rownames(fake_prcomp$rotation) <- colnames(df_num)
colnames(fake_prcomp$rotation) <- c("PC1", "PC2")
class(fake_prcomp) <- "prcomp"
df_group <- df_merged %>%
mutate(group = as.factor(!!sym(group_col))) %>%
select(group)
autoplot(fake_prcomp, data = df_group, colour = "group", frame = TRUE, frame.type = "norm",
main = paste("PCoA -", method_name)) +
theme_minimal()
}
# ==== Generate All PCoA Plots ====
pcoa_plots <- lapply(names(file_list), function(name) {
df <- read_csv(file_list[[name]])
pcoa_with_metadata_plot(df, name, metadata, group_col = "batchid")
})
# ==== Combine and Save ====
combined_pcoa <- wrap_plots(pcoa_plots, ncol = 2)
ggsave(file.path(output_folder, "pcoa.tif"), combined_pcoa, width = 12, height = 10, dpi = 300)
ggsave(file.path(output_folder, "pcoa.png"), combined_pcoa, width = 12, height = 10, dpi = 300)
# ==== Load Required Libraries ====
library(ggplot2)
library(patchwork)
library(readr)
library(dplyr)
library(ggfortify)
library(cluster)
# ==== Read UID argument ====
#args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")
if (length(args) < 1) stop("Usage: Rscript pca.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== PCA Plot Function Using Metadata Grouping ====
pca_with_metadata_plot <- function(df, method_name, metadata, group_col = "batchid") {
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
df_num <- df_merged %>%
select(where(is.numeric)) %>%
select(-any_of(group_col)) %>%
select_if(~ sd(.) > 0)  # remove constant cols
df_group <- df_merged %>%
mutate(group = as.factor(!!sym(group_col))) %>%
select(group)
pca <- prcomp(df_num, scale. = TRUE)
autoplot(
pca,
data = df_group,
colour = "group",
frame = TRUE,
frame.type = "norm",
main = paste("PCA -", method_name)
) + theme_minimal()
}
# ==== Generate PCA Plots ====
plots <- lapply(names(file_list), function(name) {
df <- read_csv(file_list[[name]])
pca_with_metadata_plot(df, name, metadata, group_col = "batchid")
})
# ==== Combine and Save ====
combined_plot <- wrap_plots(plots, ncol = 2)
ggsave(file.path(output_folder, "pca.tif"), combined_plot, width = 12, height = 10, dpi = 300)
ggsave(file.path(output_folder, "pca.png"), combined_plot, width = 12, height = 10, dpi = 300)
# ==== Load Required Libraries ====
library(vegan)
library(pheatmap)
library(readr)
library(dplyr)
library(gridExtra)
library(grid)
# ==== Handle Argument ====
# args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")  # For testing, replace with commandArgs in production
if (length(args) < 1) stop("Usage: Rscript bray-curtis_heatmap.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata <- read_csv(file.path(output_folder, "metadata.csv"))
metadata$sample_id <- as.character(metadata$sample_id)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Bray-Curtis Batch-Level Heatmap Generator ====
generate_batch_heatmap_gtable <- function(file_path, method_name, metadata, group_col = "batchid") {
df <- read_csv(file_path)
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
# Drop rows with NAs
df_merged <- df_merged %>% filter(complete.cases(.))
# Extract valid features
taxa <- df_merged %>%
select(where(is.numeric)) %>%
select_if(~ sd(., na.rm = TRUE) > 0) %>%
as.matrix()
sample_ids <- df_merged$sample_id
batches <- df_merged[[group_col]]
if (nrow(taxa) < 2 || ncol(taxa) < 1) {
warning(paste("Skipping method", method_name, "due to insufficient data."))
return(grid.text(paste("Insufficient data:", method_name)))
}
dist_mat <- vegdist(taxa, method = "bray")
dist_df <- as.matrix(dist_mat)
rownames(dist_df) <- colnames(dist_df) <- sample_ids
batch_levels <- sort(unique(batches))
batch_dist_mat <- matrix(NA, length(batch_levels), length(batch_levels),
dimnames = list(batch_levels, batch_levels))
# Compute inter-batch means
for (i in batch_levels) {
for (j in batch_levels) {
samples_i <- sample_ids[batches == i]
samples_j <- sample_ids[batches == j]
if (length(samples_i) == 0 || length(samples_j) == 0) {
batch_dist_mat[as.character(i), as.character(j)] <- NA
} else {
sub_dists <- dist_df[samples_i, samples_j, drop = FALSE]
batch_dist_mat[as.character(i), as.character(j)] <- mean(sub_dists, na.rm = TRUE)
}
}
}
# Handle NA and constant matrix
batch_dist_mat[is.na(batch_dist_mat)] <- NA
if (length(unique(na.omit(c(batch_dist_mat)))) == 1) {
batch_dist_mat <- batch_dist_mat + matrix(runif(length(batch_dist_mat), -1e-6, 1e-6),
nrow = nrow(batch_dist_mat))
}
max_val <- max(batch_dist_mat, na.rm = TRUE)
breaks <- seq(0, max_val, length.out = 101)
p <- pheatmap(
batch_dist_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 14,
fontsize = 14,
main = paste("Inter-Batch Bray-Curtis -", method_name),
color = colorRampPalette(c("blue", "white", "red"))(100),
breaks = breaks,
na_col = "gray",
silent = TRUE
)
return(p$gtable)
}
# ==== Generate Heatmaps ====
heatmap_list <- lapply(names(file_list), function(name) {
generate_batch_heatmap_gtable(file_list[[name]], name, metadata)
})
# ==== Save Combined Heatmap as TIFF ====
tiff(file.path(output_folder, "braycurtis.tif"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = heatmap_list, ncol = 2)
dev.off()
# ==== Save Combined Heatmap as PNG ====
png(file.path(output_folder, "braycurtis.png"), width = 1600, height = 1200, res = 150)
grid.arrange(grobs = heatmap_list, ncol = 2)
dev.off()
# ==== Load Libraries ====
library(pROC)
library(pheatmap)
library(readr)
library(dplyr)
library(nnet)  # for multinom
# ==== Handle Argument ====
#args <- commandArgs(trailingOnly = TRUE)
args <- c("output/example")
if (length(args) < 1) stop("Usage: Rscript auc_heatmap.R <output_folder>")
output_folder <- args[1]
# ==== Read Metadata ====
metadata_path <- file.path(output_folder, "metadata.csv")
metadata <- read_csv(metadata_path)
metadata$sample_id <- as.character(metadata$sample_id)
metadata$batchid <- as.factor(metadata$batchid)
# ==== Find All Normalized Files ====
file_paths <- list.files(output_folder, pattern = "^normalized_.*\\.csv$", full.names = TRUE)
file_list <- setNames(file_paths, gsub("^normalized_|\\.csv$", "", basename(file_paths)))
# Add Raw file explicitly
file_list <- c(Raw = file.path(output_folder, "raw.csv"), file_list)
# ==== Function to Compute AUC per Batch ====
compute_auc_matrix <- function(file_list, metadata, group_col = "batchid") {
method_names <- names(file_list)
batch_levels <- sort(unique(metadata[[group_col]]))
auc_matrix <- matrix(NA, nrow = length(method_names), ncol = length(batch_levels),
dimnames = list(method_names, paste0("Batch_", batch_levels)))
for (method in method_names) {
df <- read_csv(file_list[[method]])
df$sample_id <- metadata$sample_id
df_merged <- inner_join(df, metadata, by = "sample_id")
X <- df_merged %>% select(where(is.numeric)) %>% select_if(~ sd(.) > 0)
y <- df_merged[[group_col]]
for (b in batch_levels) {
y_bin <- as.numeric(y == b)
model <- try(glm(y_bin ~ ., data = cbind(y_bin, X), family = "binomial"), silent = TRUE)
if (!inherits(model, "try-error")) {
pred <- predict(model, newdata = X, type = "response")
roc_obj <- roc(y_bin, pred, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
auc_matrix[method, paste0("Batch_", b)] <- auc_val
}
}
}
return(auc_matrix)
}
# ==== Compute AUC Matrix ====
auc_mat <- compute_auc_matrix(file_list, metadata, group_col = "batchid")
# ==== Save Heatmap as TIFF ====
tiff(file.path(output_folder, "auc_heatmap.tif"), width = 1000, height = 800, res = 150)
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Population Effect AUC",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)
)
dev.off()
# ==== Save Heatmap as PNG ====
png(file.path(output_folder, "auc_heatmap.png"), width = 1000, height = 800, res = 150)
pheatmap(
auc_mat,
cluster_rows = FALSE,
cluster_cols = FALSE,
display_numbers = TRUE,
main = "Population Effect AUC",
fontsize_number = 12,
fontsize = 14,
color = colorRampPalette(c("white", "orange", "red"))(100),
breaks = seq(0.5, 1, length.out = 101)
)
dev.off()
