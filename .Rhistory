# ---------------------------
# Handle Arguments
# ---------------------------
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ConQuR,ALRA,ComBat", "output/0f14dd53")
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ConQuR,ALRA,ComBat", "output/0f14dd53")
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
method_list <- unlist(strsplit(args[1], ","))
output_folder <- args[2]
if (!dir.exists(output_folder)) {
dir.create(output_folder, recursive = TRUE)
}
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
# ---------------------------
# Load Data
# ---------------------------
custom_matrix_path <- file.path(output_folder, "raw.csv")
custom_metadata_path <- file.path(output_folder, "metadata.csv")
default_matrix_path <- file.path("assets", "raw.csv")
default_metadata_path <- file.path("assets", "metadata.csv")
if (file.exists(custom_matrix_path) && file.exists(custom_metadata_path)) {
cat("✅ Using uploaded user files\n")
taxa_mat <- read.csv(custom_matrix_path, check.names = FALSE)
metadata <- read.csv(custom_metadata_path)
} else {
cat("⚠️ No uploaded files found — using default assets\n")
taxa_mat <- read.csv(default_matrix_path, check.names = FALSE)
metadata <- read.csv(default_metadata_path)
}
# Ensure required metadata
required_covars <- c("sbp", "sex", "race", "age", "batchid")
missing <- setdiff(required_covars, colnames(metadata))
if (length(missing) > 0) {
stop(paste("Missing required metadata columns:", paste(missing, collapse = ", ")))
}
covar <- metadata[, c("sbp", "sex", "race", "age")]
batchid <- factor(metadata$batchid)
# ---------------------------
# Normalize Methods
# ---------------------------
if ("ConQuR" %in% method_list) {
cat("Running ConQuR...\n")
conqur_result <- ConQuR(tax_tab = taxa_mat, batchid = batchid, covariates = covar, batch_ref = "0")
write.csv(conqur_result, file.path(output_folder, "normalized_conqur.csv"), row.names = FALSE)
}
if ("ALRA" %in% method_list) {
cat("Running ALRA...\n")
taxa_filtered <- taxa_mat[rowSums(taxa_mat) > 0, ]
taxa_norm <- sweep(taxa_filtered, 1, rowSums(taxa_filtered), "/")
taxa_norm[is.na(taxa_norm)] <- 0
taxa_norm_t <- t(taxa_norm)
alra_result <- alra(taxa_norm_t)
taxa_alra <- t(alra_result$A_norm_rank_k_cor_sc)
colnames(taxa_alra) <- colnames(taxa_mat)
write.csv(taxa_alra, file.path(output_folder, "normalized_alra.csv"), row.names = FALSE)
}
if ("PLSDA" %in% method_list) {
cat("Running PLSDAbatch...\n")
rownames(taxa_mat) <- rownames(metadata)
taxa_clr <- clr(taxa_mat + 1)
Y.trt <- ifelse(metadata$sbp > 130, "high", "normal")
Y.bat <- as.factor(metadata$batchid)
result <- PLSDA_batch(X = taxa_clr, Y.trt = Y.trt, Y.bat = Y.bat, ncomp.trt = 1, ncomp.bat = 5)
write.csv(result$X.nobatch, file.path(output_folder, "normalized_plsda.csv"), row.names = FALSE)
}
if ("ComBat" %in% method_list) {
cat("Running ComBat...\n")
taxa_rel_abund <- sweep(taxa_mat, 1, rowSums(taxa_mat), "/")
taxa_rel_abund[is.na(taxa_rel_abund)] <- 0
taxa_log <- log2(taxa_rel_abund + 1e-6)
taxa_log_t <- t(taxa_log)
combat_corrected <- ComBat(dat = taxa_log_t, batch = batchid, mod = NULL, par.prior = TRUE, prior.plots = FALSE)
scaled_data <- scale(t(combat_corrected))
taxa_rel_corrected <- 2^scaled_data
write.csv(taxa_rel_corrected, file.path(output_folder, "normalized_combat.csv"), row.names = FALSE)
}
if ("FSQN" %in% method_list) {
cat("Running FSQN...\n")
reference_batch <- names(which.max(table(batchid)))
ref_matrix <- taxa_mat[batchid == reference_batch, , drop = FALSE]
reference_distribution <- apply(ref_matrix, 2, function(x) sort(x))
reference_target <- apply(reference_distribution, 1, median)
normalize_to_reference <- function(mat, target_vector) {
apply(mat, 2, function(feature_column) {
ranked <- rank(feature_column, ties.method = "min")
normalized <- target_vector[ranked]
return(normalized)
})
}
normalized_list <- lapply(unique(batchid), function(batch) {
mat <- taxa_mat[batchid == batch, , drop = FALSE]
normed <- normalize_to_reference(mat, reference_target)
rownames(normed) <- rownames(mat)
return(normed)
})
normalized_matrix <- do.call(rbind, normalized_list)
normalized_matrix <- normalized_matrix[rownames(taxa_mat), ]
write.csv(normalized_matrix, file.path(output_folder, "normalized_fsqn.csv"), row.names = FALSE)
}
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ConQuR,ALRA,PLSDA,ComBat,FSQN", "output/0f14dd53")
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
method_list <- unlist(strsplit(args[1], ","))
output_folder <- args[2]
if (!dir.exists(output_folder)) {
dir.create(output_folder, recursive = TRUE)
}
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
# ---------------------------
# Load Data
# ---------------------------
custom_matrix_path <- file.path(output_folder, "raw.csv")
custom_metadata_path <- file.path(output_folder, "metadata.csv")
default_matrix_path <- file.path("assets", "raw.csv")
default_metadata_path <- file.path("assets", "metadata.csv")
if (file.exists(custom_matrix_path) && file.exists(custom_metadata_path)) {
cat("✅ Using uploaded user files\n")
taxa_mat <- read.csv(custom_matrix_path, check.names = FALSE)
metadata <- read.csv(custom_metadata_path)
} else {
cat("⚠️ No uploaded files found — using default assets\n")
taxa_mat <- read.csv(default_matrix_path, check.names = FALSE)
metadata <- read.csv(default_metadata_path)
write.csv(taxa_mat, file = file.path(output_folder, "raw.csv"), row.names = FALSE)
write.csv(metadata, file = file.path(output_folder, "metadata.csv"), row.names = FALSE)
}
# Ensure required metadata
required_columns <- c("sample_id", "batchid")
missing <- setdiff(required_columns, colnames(metadata))
if (length(missing) > 0) {
stop(paste("Missing required metadata columns:", paste(missing, collapse = ", ")))
}
covar <- metadata[, !(colnames(metadata) %in% c("sample_id", "batchid")), drop = FALSE]
batchid <- factor(metadata$batchid)
# ---------------------------
# Normalize Methods
# ---------------------------
if ("ConQuR" %in% method_list) {
cat("Running ConQuR...\n")
conqur_result <- ConQuR(tax_tab = taxa_mat, batchid = batchid, covariates = covar, batch_ref = "0")
write.csv(conqur_result, file.path(output_folder, "normalized_conqur.csv"), row.names = FALSE)
}
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ALRA,PLSDA,ComBat,FSQN", "output/0f14dd53")
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
method_list <- unlist(strsplit(args[1], ","))
output_folder <- args[2]
if (!dir.exists(output_folder)) {
dir.create(output_folder, recursive = TRUE)
}
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
# ---------------------------
# Load Data
# ---------------------------
custom_matrix_path <- file.path(output_folder, "raw.csv")
custom_metadata_path <- file.path(output_folder, "metadata.csv")
default_matrix_path <- file.path("assets", "raw.csv")
default_metadata_path <- file.path("assets", "metadata.csv")
if (file.exists(custom_matrix_path) && file.exists(custom_metadata_path)) {
cat("✅ Using uploaded user files\n")
taxa_mat <- read.csv(custom_matrix_path, check.names = FALSE)
metadata <- read.csv(custom_metadata_path)
} else {
cat("⚠️ No uploaded files found — using default assets\n")
taxa_mat <- read.csv(default_matrix_path, check.names = FALSE)
metadata <- read.csv(default_metadata_path)
write.csv(taxa_mat, file = file.path(output_folder, "raw.csv"), row.names = FALSE)
write.csv(metadata, file = file.path(output_folder, "metadata.csv"), row.names = FALSE)
}
# Ensure required metadata
required_columns <- c("sample_id", "batchid")
missing <- setdiff(required_columns, colnames(metadata))
if (length(missing) > 0) {
stop(paste("Missing required metadata columns:", paste(missing, collapse = ", ")))
}
covar <- metadata[, !(colnames(metadata) %in% c("sample_id", "batchid")), drop = FALSE]
batchid <- factor(metadata$batchid)
# ---------------------------
# Normalize Methods
# ---------------------------
if ("ConQuR" %in% method_list) {
cat("Running ConQuR...\n")
conqur_result <- ConQuR(tax_tab = taxa_mat, batchid = batchid, covariates = covar, batch_ref = "0")
write.csv(conqur_result, file.path(output_folder, "normalized_conqur.csv"), row.names = FALSE)
}
if ("ALRA" %in% method_list) {
cat("Running ALRA...\n")
taxa_filtered <- taxa_mat[rowSums(taxa_mat) > 0, ]
taxa_norm <- sweep(taxa_filtered, 1, rowSums(taxa_filtered), "/")
taxa_norm[is.na(taxa_norm)] <- 0
taxa_norm_t <- t(taxa_norm)
alra_result <- alra(taxa_norm_t)
taxa_alra <- t(alra_result$A_norm_rank_k_cor_sc)
colnames(taxa_alra) <- colnames(taxa_mat)
write.csv(taxa_alra, file.path(output_folder, "normalized_alra.csv"), row.names = FALSE)
}
if ("PLSDA" %in% method_list) {
cat("Running PLSDAbatch...\n")
rownames(taxa_mat) <- rownames(metadata)
taxa_clr <- clr(taxa_mat + 1)
Y.trt <- ifelse(metadata$sbp > 130, "high", "normal")
Y.bat <- as.factor(metadata$batchid)
result <- PLSDA_batch(X = taxa_clr, Y.trt = Y.trt, Y.bat = Y.bat, ncomp.trt = 1, ncomp.bat = 5)
write.csv(result$X.nobatch, file.path(output_folder, "normalized_plsda.csv"), row.names = FALSE)
}
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ALRA,PLSDA,ComBat,FSQN", "output/0f14dd53")
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
method_list <- unlist(strsplit(args[1], ","))
output_folder <- args[2]
if (!dir.exists(output_folder)) {
dir.create(output_folder, recursive = TRUE)
}
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
# ---------------------------
# Load Data
# ---------------------------
custom_matrix_path <- file.path(output_folder, "raw.csv")
custom_metadata_path <- file.path(output_folder, "metadata.csv")
default_matrix_path <- file.path("assets", "raw.csv")
default_metadata_path <- file.path("assets", "metadata.csv")
if (file.exists(custom_matrix_path) && file.exists(custom_metadata_path)) {
cat("✅ Using uploaded user files\n")
taxa_mat <- read.csv(custom_matrix_path, check.names = FALSE)
metadata <- read.csv(custom_metadata_path)
} else {
cat("⚠️ No uploaded files found — using default assets\n")
taxa_mat <- read.csv(default_matrix_path, check.names = FALSE)
metadata <- read.csv(default_metadata_path)
write.csv(taxa_mat, file = file.path(output_folder, "raw.csv"), row.names = FALSE)
write.csv(metadata, file = file.path(output_folder, "metadata.csv"), row.names = FALSE)
}
# Ensure required metadata
required_columns <- c("sample_id", "batchid")
missing <- setdiff(required_columns, colnames(metadata))
if (length(missing) > 0) {
stop(paste("Missing required metadata columns:", paste(missing, collapse = ", ")))
}
covar <- metadata[, !(colnames(metadata) %in% c("sample_id", "batchid")), drop = FALSE]
batchid <- factor(metadata$batchid)
# ---------------------------
# Normalize Methods
# ---------------------------
if ("ConQuR" %in% method_list) {
cat("Running ConQuR...\n")
conqur_result <- ConQuR(tax_tab = taxa_mat, batchid = batchid, covariates = covar, batch_ref = "0")
write.csv(conqur_result, file.path(output_folder, "normalized_conqur.csv"), row.names = FALSE)
}
if ("ALRA" %in% method_list) {
cat("Running ALRA...\n")
taxa_filtered <- taxa_mat[rowSums(taxa_mat) > 0, ]
taxa_norm <- sweep(taxa_filtered, 1, rowSums(taxa_filtered), "/")
taxa_norm[is.na(taxa_norm)] <- 0
taxa_norm_t <- t(taxa_norm)
alra_result <- alra(taxa_norm_t)
taxa_alra <- t(alra_result$A_norm_rank_k_cor_sc)
colnames(taxa_alra) <- colnames(taxa_mat)
write.csv(taxa_alra, file.path(output_folder, "normalized_alra.csv"), row.names = FALSE)
}
if ("PLSDA" %in% method_list) {
print("Running PLSDAbatch...")
rownames(taxa_mat) <- rownames(metadata)
taxa_clr <- clr(taxa_mat + 1)
Y.trt <- ifelse(metadata$batchid == 0, "control", "treatment")
Y.bat <- as.factor(metadata$batchid)
result <- PLSDA_batch(X = taxa_clr, Y.trt = Y.trt, Y.bat = Y.bat, ncomp.trt = 1, ncomp.bat = 5)
write.csv(result$X.nobatch, file.path(output_folder, "normalized_plsda.csv"), row.names = FALSE)
}
if ("ComBat" %in% method_list) {
cat("Running ComBat...\n")
taxa_rel_abund <- sweep(taxa_mat, 1, rowSums(taxa_mat), "/")
taxa_rel_abund[is.na(taxa_rel_abund)] <- 0
taxa_log <- log2(taxa_rel_abund + 1e-6)
taxa_log_t <- t(taxa_log)
combat_corrected <- ComBat(dat = taxa_log_t, batch = batchid, mod = NULL, par.prior = TRUE, prior.plots = FALSE)
scaled_data <- scale(t(combat_corrected))
taxa_rel_corrected <- 2^scaled_data
write.csv(taxa_rel_corrected, file.path(output_folder, "normalized_combat.csv"), row.names = FALSE)
}
if ("FSQN" %in% method_list) {
cat("Running FSQN...\n")
reference_batch <- names(which.max(table(batchid)))
ref_matrix <- taxa_mat[batchid == reference_batch, , drop = FALSE]
reference_distribution <- apply(ref_matrix, 2, function(x) sort(x))
reference_target <- apply(reference_distribution, 1, median)
normalize_to_reference <- function(mat, target_vector) {
apply(mat, 2, function(feature_column) {
ranked <- rank(feature_column, ties.method = "min")
normalized <- target_vector[ranked]
return(normalized)
})
}
normalized_list <- lapply(unique(batchid), function(batch) {
mat <- taxa_mat[batchid == batch, , drop = FALSE]
normed <- normalize_to_reference(mat, reference_target)
rownames(normed) <- rownames(mat)
return(normed)
})
normalized_matrix <- do.call(rbind, normalized_list)
normalized_matrix <- normalized_matrix[rownames(taxa_mat), ]
write.csv(normalized_matrix, file.path(output_folder, "normalized_fsqn.csv"), row.names = FALSE)
}
# ---------------------------
# Handle Arguments
# ---------------------------
#args <- commandArgs(trailingOnly = TRUE)
args <- c("ConQuR,ALRA,PLSDA,ComBat,FSQN", "output/0f14dd53")
if (length(args) < 2) {
stop("Usage: Rscript normalize_all_methods.R <method_list> <output_folder>")
}
method_list <- unlist(strsplit(args[1], ","))
output_folder <- args[2]
if (!dir.exists(output_folder)) {
dir.create(output_folder, recursive = TRUE)
}
# ---------------------------
# Load Libraries
# ---------------------------
library(ConQuR)
library(foreach)
library(doParallel)
library(dplyr)
library(Matrix)
library(SummarizedExperiment)
library(S4Vectors)
library(compositions)
suppressWarnings({
require(ALRA)
require(BDMMAcorrect)
require(PLSDAbatch)
require(sva)
require(FSQN)
})
# ---------------------------
# Load Data
# ---------------------------
custom_matrix_path <- file.path(output_folder, "raw.csv")
custom_metadata_path <- file.path(output_folder, "metadata.csv")
default_matrix_path <- file.path("assets", "raw.csv")
default_metadata_path <- file.path("assets", "metadata.csv")
if (file.exists(custom_matrix_path) && file.exists(custom_metadata_path)) {
cat("✅ Using uploaded user files\n")
taxa_mat <- read.csv(custom_matrix_path, check.names = FALSE)
metadata <- read.csv(custom_metadata_path)
} else {
cat("⚠️ No uploaded files found — using default assets\n")
taxa_mat <- read.csv(default_matrix_path, check.names = FALSE)
metadata <- read.csv(default_metadata_path)
write.csv(taxa_mat, file = file.path(output_folder, "raw.csv"), row.names = FALSE)
write.csv(metadata, file = file.path(output_folder, "metadata.csv"), row.names = FALSE)
}
# Ensure required metadata
required_columns <- c("sample_id", "batchid")
missing <- setdiff(required_columns, colnames(metadata))
if (length(missing) > 0) {
stop(paste("Missing required metadata columns:", paste(missing, collapse = ", ")))
}
covar <- metadata[, !(colnames(metadata) %in% c("sample_id", "batchid")), drop = FALSE]
batchid <- factor(metadata$batchid)
# ---------------------------
# Normalize Methods
# ---------------------------
if ("ConQuR" %in% method_list) {
cat("Running ConQuR...\n")
conqur_result <- ConQuR(tax_tab = taxa_mat, batchid = batchid, covariates = covar, batch_ref = "0")
write.csv(conqur_result, file.path(output_folder, "normalized_conqur.csv"), row.names = FALSE)
}
